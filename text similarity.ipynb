{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for downloading content from the web\n",
    "def content_downloader(url):\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.content, \"lxml\") \n",
    "    return str(soup.find(\"div\", {\"class\": \"postArticle-content js-postField js-notesSource js-trackedPost\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the content and return sentences it's not compelete and need to be modified\n",
    "def cleaning_text(text):\n",
    "#     text = re.sub('<[A-Za-z\\/][^>]*>', ' ', str())\n",
    "#     text = re.split(r'\\s{2,}', text)\n",
    "#     return text[1:-1]\n",
    "#     nlp = spacy.load('en_core_web_sm')\n",
    "#     doc = nlp(text)\n",
    "#     list_of_sentences = []\n",
    "#     for sentence in doc.sents:\n",
    "#         list_of_sentences.append(sentence)\n",
    "#     return list_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "text = contentDownloader('https://towardsdatascience.com/5-resources-to-inspire-your-next-data-science-project-ea6afbe20319')\n",
    "print('\\xa0' in text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading diffrenet module\n",
    "def loading_module(module_url):\n",
    "    # Import the Universal Sentence Encoder's TF Hub module\n",
    "    embed = hub.Module(module_url)\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for runinng embedding module on text\n",
    "def run_embedding(embed_object, text):\n",
    "    # Reduce logging output.\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        message_embeddings = session.run(embed_object(text))\n",
    "\n",
    "    return message_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating similarity between question and text\n",
    "def calculating_text_similarity(question, text, module_url):\n",
    "    question = cleaning_text(question)\n",
    "    text = cleaning_text(text)\n",
    "    question_tensor = tf.Variable(tf.convert_to_tensor(run_embedding(loading_module(module_url), question)))\n",
    "    text_tensor = tf.Variable(tf.convert_to_tensor(run_embedding(loading_module(module_url), text)))\n",
    "    multiply_tensor = tf.matmul(question_tensor, text_tensor, transpose_b = True)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        answer = sess.run(multiply_tensor)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for find sentence in text that answer question that has been asked\n",
    "def find_similar_sentence(similarity_tensor, question, text):\n",
    "    text = np.array(text)\n",
    "    question_and_text = np.hstack([question, text]).reshape(-1, 1)\n",
    "    print(question_and_text)\n",
    "    return text[np.argmax(similarity_tensor)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
