{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for downloading content from the web\n",
    "def content_downloader(url):\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.content, \"lxml\") \n",
    "    return str(soup.find(\"div\", {\"class\": \"postArticle-content js-postField js-notesSource js-trackedPost\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the content and return sentences it's not compelete and need to be modified\n",
    "def cleaning_text(html_part):\n",
    "    text = re.sub('<[A-Za-z\\/][^>]*>', ' ', str(html_part))\n",
    "    text = re.split(r'\\s{2,}', text)[1:-1]\n",
    "    text = [sentence.replace('\\xa0', ' ') for sentence in text]\n",
    "    text = [sentence.replace('\\u200aâ€”\\u200a', ' ') for sentence in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing a text for execute caculations on it\n",
    "def prepare_text_from_html(url):\n",
    "    html_content = content_downloader(url)\n",
    "    text = cleaning_text(html_content)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading diffrenet module\n",
    "def loading_module(module_url):\n",
    "    # Import the Universal Sentence Encoder's TF Hub module\n",
    "    embed_object = hub.Module(module_url)\n",
    "    return embed_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for runinng embedding module on text\n",
    "def run_embedding(embed_object, text):\n",
    "    # Reduce logging output.\n",
    "    tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        message_embeddings = session.run(embed_object(text))\n",
    "\n",
    "    return message_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for calculating similarity between question and text\n",
    "def calculating_similarity_tensor(module_url, question, text):\n",
    "    question_tensor = tf.Variable(tf.convert_to_tensor(run_embedding(loading_module(module_url), question)))\n",
    "    text_tensor = tf.Variable(tf.convert_to_tensor(run_embedding(loading_module(module_url), text)))\n",
    "    multiply_tensor = tf.matmul(question_tensor, text_tensor, transpose_b = True)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        answer = sess.run(multiply_tensor)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for find sentence in text that answer question that has been asked\n",
    "def find_similar_sentence(similarity_tensor, question, text):\n",
    "    print('similarity score for the most similar sentence is {}'.format(np.max(similarity_tensor)))\n",
    "    return np.hstack([question, text[np.argmax(similarity_tensor)]]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for printing information about similarity tensor and printing a stack of similar sentences from text to question\n",
    "def print_information(similarity_tensor, question, text, threshold = 0.7):\n",
    "    print(np.array(list(zip(similarity_tensor[0], text))))\n",
    "    sorted_similarity_array = np.array([list(row) for row in sorted(zip(similarity_tensor[0], text), reverse = True)])\n",
    "    if threshold == 0:\n",
    "        print(sorted_similarity_tensor)\n",
    "    sorted_similarity_text = np.split(sorted_similarity_array, 2, axis = 1)[1]\n",
    "    sorted_similarity_tensor = np.split(sorted_similarity_array, 2, axis = 1)[0].flatten().astype('float')\n",
    "    sentences = [sorted_similarity_text[i] for i in np.where(sorted_similarity_tensor > threshold)[0]]\n",
    "    return np.vstack([question, sentences]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_phase(phase):\n",
    "    print(phase)\n",
    "    print('=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=*=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for comparing two different modules from tensorflow hub on same question and text\n",
    "def calculate_different_model_accuracy(module_url_1, module_url_2, question, text):\n",
    "    similarity_tensor_1 = calculating_similarity_tensor(module_url_1, question, text)\n",
    "    similarity_tensor_2 = calculating_similarity_tensor(module_url_2, question, text)\n",
    "    similar_sentence_1 = find_similar_sentence(similarity_tensor_1, question, text)\n",
    "    print_phase(similar_sentence_1)\n",
    "    similar_sentence_2 = find_similar_sentence(similarity_tensor_2, question, text)\n",
    "    print_phase(similar_sentence_2)\n",
    "    information_1 = print_information(similarity_tensor_1, question, text, threshold = 0.8)\n",
    "    print_phase(information_1)\n",
    "    information_2 = print_information(similarity_tensor_2, question, text, threshold = 0.8)\n",
    "    print_phase(information_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = prepare_text_from_html('https://towardsdatascience.com/5-resources-to-inspire-your-next-data-science-project-ea6afbe20319')\n",
    "question = '5 Resources to Inspire Your Next Data Science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for prepare data for input functions for tensorflow DNN classifier\n",
    "def prepare_dataset_for_finetuning(text, question):\n",
    "    x = text\n",
    "    y = np.arange(len(x))\n",
    "    x = np.hstack([question, text])\n",
    "    y = np.insert(y, 0, 0)\n",
    "    x = pd.DataFrame(x,\n",
    "        index = pd.RangeIndex(1, len(x) + 1),\n",
    "        columns = ['sentences'])\n",
    "    x['class'] = pd.Series(y, index = x.index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for prepare functions for tensorflow DNN classifier\n",
    "def prepare_input_function(data):\n",
    "    train_input_function = tf.estimator.inputs.pandas_input_fn(data, data['class'], num_epochs = None, shuffle = True)\n",
    "    predict_input_function = tf.estimator.inputs.pandas_input_fn(data, data['class'], shuffle = False)\n",
    "    return train_input_function, predict_input_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for training a DNN classifier base on tensorflow hub text modules\n",
    "def train_and_evaluate_with_module(hub_module, text, question, trainable = True):\n",
    "    data = prepare_dataset_for_finetuning(text, question)\n",
    "    train_input_function = prepare_input_function(data)[0]\n",
    "    predict_input_function = prepare_input_function(data)[1]\n",
    "    \n",
    "    embedded_text_feature_column = hub.text_embedding_column(key = 'sentences', module_spec = hub_module, trainable = trainable)\n",
    "    \n",
    "    estimator = tf.estimator.DNNClassifier(\n",
    "        hidden_units = [500, 100],\n",
    "        feature_columns = embedded_text_feature_column,\n",
    "        n_classes = 83,\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate = 0.003))\n",
    "    \n",
    "    estimator.train(input_fn = train_input_function, steps = 1000)\n",
    "    \n",
    "    train_eval_result = estimator.evaluate(input_fn = predict_input_function)\n",
    "    training_eval_accuracy = train_eval_result['accuracy']\n",
    "    \n",
    "    return training_eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
